{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b34ad4-1575-4a2b-8670-16f03eb8edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.nodes import PreProcessor, TransformersDocumentClassifier, FARMReader, BM25Retriever\n",
    "from haystack.schema import Document\n",
    "from haystack.utils import convert_files_to_docs, fetch_archive_from_http, print_answers\n",
    "\n",
    "doc_dir = \"/mnt/sda/haystack/enrich_data\"\n",
    "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/preprocessing_tutorial16.zip\"\n",
    "fetch_archive_from_http(url = s3_url, output_dir = doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6a5a2-561b-4975-b7b4-dee46ece2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIme to pre process. Note that you can also use the document classifier before applying the PreProcessor, e.g. before splitting your documents\n",
    "\n",
    "all_docs = convert_files_to_docs(dir_path = doc_dir)\n",
    "preprocessor_sliding_window = PreProcessor(split_overlap = 3, split_length = 10, split_respect_sentence_boundary = False)\n",
    "docs_sliding_window = preprocessor_sliding_window.process(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb8fa6-d25d-4939-8f5e-2018f1ef0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_classifier = TransformersDocumentClassifier(\n",
    "    model_name_or_path = \"cross-encoder/nli-distilroberta-base\",\n",
    "    task = \"zero-shot-classification\",\n",
    "    labels = [\"music\", \"natural language processing\", \"history\"],\n",
    "    batch_size = 16,\n",
    ")\n",
    "\n",
    "# classify using gpu, batch_size makes sure we do not run out of memory\n",
    "classified_docs = doc_classifier.predict(docs_sliding_window)\n",
    "print(classified_docs[0].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527a649-e7d5-46cb-a5df-dd7b06bf7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DocumentStore and index documents\n",
    "document_store = ElasticsearchDocumentStore(host = \"localhost\", port = 9200, username=\"elastic\", \n",
    "    password=\"cMYVjbUMj_8_664gC6R8\", index = \"document\", scheme = \"https\", verify_certs = True,\n",
    "    ca_certs = \"/home/tanvir/work/qa-experiment/http_ca.crt\")\n",
    "\n",
    "document_store.delete_all_documents()\n",
    "document_store.write_documents(classified_docs)\n",
    "\n",
    "# check if indexed docs contain classification results\n",
    "test_doc = document_store.get_all_documents()[0]\n",
    "print(f'document {test_doc.id} with content \\n\\n{test_doc.content}\\n\\nhas label {test_doc.meta[\"classification\"][\"label\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347c69b-b84b-4961-b63c-de5b3f5baed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For querying the data, all we have to do to filter for one of our classes is to set a filter on \"classification.label\".\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "retriever = BM25Retriever(document_store = document_store)\n",
    "reader = FARMReader(model_name_or_path = \"deepset/roberta-base-squad2\", use_gpu = True)\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)\n",
    "\n",
    "prediction = pipe.run(\n",
    "    query = \"What is heavy metal?\",\n",
    "    params = {\"Retriever\": {\"top_k\": 10, \"filters\": {\"classification.label\": [\"music\"]}}, \"Reader\": {\"top_k\": 5}},\n",
    ")\n",
    "\n",
    "print_answers(prediction, details = \"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26e5111-1a2a-48cb-b03a-2bc5d8a54cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pdftotext version 22.02.0\n",
      "Copyright 2005-2022 The Poppler Developers - http://poppler.freedesktop.org\n",
      "Copyright 1996-2011 Glyph & Cog, LLC\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 160.18docs/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.67docs/s]\n",
      "/home/tanvir/work/qa-experiment/.env/lib/python3.8/site-packages/transformers/pipelines/base.py:996: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3228.87docs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Document: {'content': 'Classics or classical studies is the study of classical antiquity,', 'content_type': 'text', 'score': None, 'meta': {'_split_id': 0, 'classification': {'sequence': 'Classics or classical studies is the study of classical antiquity,', 'labels': ['music', 'natural language processing', 'history'], 'scores': [0.3458789885044098, 0.3373076319694519, 0.3168133497238159], 'label': 'music'}}, 'embedding': None, 'id': '5f06721d4e5ddd207e8de318274a89b6'}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets wrap everything up with an indexing pipeline\n",
    "\n",
    "from pathlib import Path\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import TextConverter, PreProcessor, FileTypeClassifier, PDFToTextConverter, DocxToTextConverter\n",
    "\n",
    "file_type_classifier = FileTypeClassifier()\n",
    "text_converter = TextConverter()\n",
    "pdf_converter = PDFToTextConverter()\n",
    "docx_converter = DocxToTextConverter()\n",
    "\n",
    "indexing_pipeline_with_classification = Pipeline()\n",
    "indexing_pipeline_with_classification.add_node(component = file_type_classifier, name = \"FileTypeClassifier\", inputs = [\"File\"])\n",
    "indexing_pipeline_with_classification.add_node(component = text_converter, name = \"TextConverter\", inputs = [\"FileTypeClassifier.output_1\"])\n",
    "indexing_pipeline_with_classification.add_node(component = pdf_converter, name = \"PdfConverter\", inputs = [\"FileTypeClassifier.output_2\"])\n",
    "indexing_pipeline_with_classification.add_node(component = docx_converter, name = \"DocxConverter\", inputs = [\"FileTypeClassifier.output_4\"])\n",
    "indexing_pipeline_with_classification.add_node(component = preprocessor_sliding_window, name = \"Preprocessor\", inputs = [\"TextConverter\", \"PdfConverter\", \"DocxConverter\"])\n",
    "indexing_pipeline_with_classification.add_node(component = doc_classifier, name = \"DocumentClassifier\", inputs = [\"Preprocessor\"])\n",
    "indexing_pipeline_with_classification.add_node(component = document_store, name = \"DocumentStore\", inputs = [\"DocumentClassifier\"])\n",
    "\n",
    "document_store.delete_documents()\n",
    "txt_files = [f for f in Path(doc_dir).iterdir() if f.suffix == \".txt\"]\n",
    "pdf_files = [f for f in Path(doc_dir).iterdir() if f.suffix == \".pdf\"]\n",
    "docx_files = [f for f in Path(doc_dir).iterdir() if f.suffix == \".docx\"]\n",
    "indexing_pipeline_with_classification.run(file_paths = txt_files)\n",
    "indexing_pipeline_with_classification.run(file_paths = pdf_files)\n",
    "indexing_pipeline_with_classification.run(file_paths = docx_files)\n",
    "\n",
    "document_store.get_all_documents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b170a51-ae2e-497b-af4c-dba236670088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can store this pipeline in a yaml file\n",
    "indexing_pipeline_with_classification.save_to_yaml(\"indexing_pipeline_with_classification.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186ec01-761b-47f0-9792-00b476baa333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
