{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316cfbb-dc92-4330-a4b1-e62ee9050da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a subset of Amazon office product review dataset. For our example, we’ll be working with a subset of the Amazon Review Dataset\n",
    "# that consists of around 50,000 reviews of items from Amazon’s office supplies category (http://jmcauley.ucsd.edu/data/amazon/links.html)\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "file_path = \"/mnt/sda/haystack/amazon_data/reviews_Office_Products_5.json\"\n",
    "\n",
    "reviews = pd.read_json(file_path, lines = True)\n",
    "# print(reviews.columns)\n",
    "\n",
    "# Extract review text and ids and convert them into a dictionary. The meta field contains item_id\n",
    "# which will be used for filtering later.\n",
    "texts = reviews.reviewText.values\n",
    "ids = reviews.asin.values\n",
    "\n",
    "dicts = [{'content': text, 'meta': {'item_id': id_}} for text, id_ in zip(texts, ids)]\n",
    "\n",
    "random.choice(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15aa8c-ce12-4a43-8a58-3d4e2b369c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we’re going to work with the dense DPR retrieval method, we let the preprocessor split\n",
    "# our reviews into chunks of length 100 and an overlap of five words.\n",
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "processor = PreProcessor(\n",
    "    split_by = 'word', \n",
    "    split_length = 100,\n",
    "    split_respect_sentence_boundary = False,\n",
    "    split_overlap = 5)\n",
    "flattened_docs = processor.process(dicts)\n",
    "\n",
    "random.choice(flattened_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881ae9f-34f7-47c1-b568-b4c7238c84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in elastic\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(host = \"localhost\", port = 9200, username = \"elastic\", \n",
    "    password = \"Dkmh=pOI=CSukfWwOoxh\", index = \"document\", scheme = \"https\", verify_certs = True,\n",
    "    ca_certs = \"/home/tanvir/work/qa-experiment/http_ca.crt\")\n",
    "document_store.delete_documents()\n",
    "document_store.write_documents(flattened_docs)\n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a3122-63dc-4074-9d04-d08bae628711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the dense passage retriever and update embeddings.\n",
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store = document_store,\n",
    "    query_embedding_model = \"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model = \"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    max_seq_len_query = 64,\n",
    "    max_seq_len_passage = 256,\n",
    "    batch_size = 16,\n",
    "    use_gpu = True,\n",
    "    embed_title = True,\n",
    "    use_fast_tokenizers = True,\n",
    ")\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b53e4-ef19-4cb0-9766-5f589a9d0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "import os\n",
    "\n",
    "# Supress the warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "reader = FARMReader(model_name_or_path = \"deepset/roberta-base-squad2\", use_gpu = True, return_no_answer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16941b20-5b52-476a-8714-0d4fc92a8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pipeline\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "pipeline = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6372e-0160-4361-8323-6d23a53ca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick peek at the item with most reviews\n",
    "reviews.groupby('asin').size().sort_values(ascending = False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452d653-dba7-43f5-863a-6671242e6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In total we have 311 reviews for item id 'B0010T3QT2' (some kind of envelope).\n",
    "# Lets invoke the pipeline with the filter with item id.\n",
    "from haystack.utils import print_answers\n",
    "import time\n",
    "filter = {'item_id': ['B0010T3QT2']}\n",
    "q = 'How well does this envelope stick?'\n",
    "start_time = time.process_time()\n",
    "answers = pipeline.run(q, params = {\"Retriever\": {\"top_k\": 30}, \"Reader\": {\"top_k\": 10}, \"filters\": filter})\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(f\"Time taken with filter: {elapsed_time} seconds\")\n",
    "print_answers(answers, details = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4c982-e342-4f48-a9d1-2613dcf4a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets run the same query without filters. It should take slightly longer but the answers won't be super relevant\n",
    "start_time = time.process_time()\n",
    "answers = pipeline.run(q, params = {\"Retriever\": {\"top_k\": 30}, \"Reader\": {\"top_k\": 10}})\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(f\"Time taken without filter: {elapsed_time} seconds\")\n",
    "print_answers(answers, details = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82498cc8-137e-45e2-9215-43a7988d4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its possible to filter across multiple products to find answers about a product category\n",
    "filter_mutiple = {'item_id': ['B00006IBLJ', 'B000GHJM9C', 'B000CS787S']}\n",
    "q2 = 'Can things still break when they\\'re wrapped in bubble wrap?'\n",
    "start_time = time.process_time()\n",
    "answers = pipeline.run(q2, params = {\"Retriever\": {\"top_k\": 100}, \"Reader\": {\"top_k\": 3}, \"filters\": filter_mutiple})\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(f\"Time taken with multi-filter: {elapsed_time} seconds\")\n",
    "print_answers(answers, details = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee995c-11f7-4f7e-8e64-1f8523bc64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA is great but Haystack also works as a just retriever pipeline. Lets run the same set of experiments\n",
    "# for the retriever pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc2b48-8420-413e-81fe-db8bcd96f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering on one product id\n",
    "from haystack.pipelines import DocumentSearchPipeline\n",
    "from haystack.utils import print_documents\n",
    "\n",
    "search_pipeline = DocumentSearchPipeline(retriever)\n",
    "search_query = \"Easy to seal but hard to use\"\n",
    "start_time = time.process_time()\n",
    "search_result = search_pipeline.run(search_query, params = {\"Retriever\": {\"top_k\": 10}, \"filters\": filter})\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(f\"Time taken with multi: {elapsed_time} seconds\")\n",
    "print_documents(search_result, max_text_len = 100, print_name = True, print_meta = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca3d77-1b07-49ca-b035-00f984461c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever without filter\n",
    "start_time = time.process_time()\n",
    "search_result = search_pipeline.run(search_query, params = {\"Retriever\": {\"top_k\": 10}})\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(f\"Time taken without filter: {elapsed_time} seconds\")\n",
    "print_documents(search_result, max_text_len = 100, print_name = True, print_meta = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f584cd-deac-4110-a36c-2f098376bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its possible to filter across multiple products to find answers about a product category\n",
    "filter_mutiple = {'item_id': ['B00006IBLJ', 'B000GHJM9C', 'B000CS787S']}\n",
    "start_time = time.process_time()\n",
    "search_result = search_pipeline.run(search_query, params = {\"Retriever\": {\"top_k\": 10}, \"filters\": filter_mutiple})\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(f\"Time taken with multi-filter: {elapsed_time} seconds\")\n",
    "print_documents(search_result, max_text_len = 100, print_name = True, print_meta = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e6566049-d1a9-4d90-9c98-268be436d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filters: 0 - Execution time: 0.12494182799969167\n",
      "Number of filters: 1 - Execution time: 0.10182105299986688\n",
      "Number of filters: 2 - Execution time: 0.09505063100004918\n",
      "Number of filters: 3 - Execution time: 0.09579995000012786\n",
      "Number of filters: 4 - Execution time: 0.09451272500041341\n",
      "Number of filters: 5 - Execution time: 0.09400194499994541\n",
      "Number of filters: 6 - Execution time: 0.09281263899993064\n",
      "Number of filters: 7 - Execution time: 0.09322232299996358\n",
      "Number of filters: 8 - Execution time: 0.09555610299980799\n",
      "Number of filters: 9 - Execution time: 0.09571709099986947\n",
      "Number of filters: 10 - Execution time: 0.09547573099962392\n"
     ]
    }
   ],
   "source": [
    "# Lets plot how adding more filters is related to query execution time.\n",
    "def calculate_retrieval_time(item_id_list, query_list):\n",
    "    total_time = 0.0\n",
    "    for q in query_list:\n",
    "        start_time = time.process_time()\n",
    "        search_result = search_pipeline.run(q, params = {\"Retriever\": {\"top_k\": 10}, \"filters\": {'item_id': item_id_list}})\n",
    "        total_time += (time.process_time() - start_time)\n",
    "    return total_time\n",
    "\n",
    "query_list = [\n",
    "    'Office supplies are expensive',\n",
    "    'Stapler is broken',\n",
    "    'Printer does not work',\n",
    "    'Erasers are too abrasive'\n",
    "    'Easy to seal but hard to use'\n",
    "]\n",
    "item_id_list = ['B00006IBLJ', 'B000GHJM9C', 'B000CS787S',\n",
    "                'B00004Z59A', 'B000KKMO90', 'B004JDI1I2',\n",
    "                'B003155XYO', 'B002VUCCNU', 'B00066FHNI', \n",
    "                'B003VNE25M']\n",
    "\n",
    "query_item_id_list = []\n",
    "for i in range(11):\n",
    "    total = calculate_retrieval_time(query_item_id_list, query_list)\n",
    "    print(f\"Number of filters: {len(query_item_id_list)} - Execution time: {total}\")\n",
    "    if i < 10:\n",
    "        query_item_id_list.append(item_id_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f454ef5-ebf1-4fbe-9b0d-e56366c1e7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
